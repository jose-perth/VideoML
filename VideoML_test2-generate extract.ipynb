{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on handling video file in Python\n",
    "## Use trained model to detect character and extract section of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use 1st video file to train model, sample 1 frame per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder = \"./SampleVideo/\"\n",
    "outputFolder = \"./OutputVideo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 26,348,035\n",
      "Trainable params: 26,348,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# output layer has 3 neurons as we have 3 classes to predict.\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))\n",
    "model.add(Dense(units=1024, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=512, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=256, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "#model.summary()\n",
    "model.load_weights(\"best_model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pretrained model VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))   #top layer not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category  FrameID  StartTime\n",
      "0       2.0    145.0        0.0\n",
      "1       2.0   1044.0        3.0\n",
      "2       2.0   1624.0       18.0\n",
      "3       2.0   1682.0       28.0\n",
      "4       2.0   1740.0       29.0\n",
      "5       2.0   3306.0       30.0\n"
     ]
    }
   ],
   "source": [
    "videoFile = inputFolder + \"Tom and Jerry 3.mp4\"\n",
    "categoryToFind = 1    # Interested in finding Jerry\n",
    "extractTime = 2 #sec\n",
    "framesToSkipIfFound = \n",
    "\n",
    "df = pd.DataFrame(columns = ['Category','FrameID','StartTime'])\n",
    "\n",
    "# Create handle for video\n",
    "capture = cv2.VideoCapture(videoFile)\n",
    "frameRate = capture.get(5)\n",
    "samplingRate = math.floor(frameRate)\n",
    "\n",
    "# Iterate through video and position of 1st character\n",
    "\n",
    "found = False\n",
    "startTime = 0\n",
    "count = 0\n",
    "skipToCount = 0\n",
    "while(capture.isOpened()):\n",
    "    frameId = capture.get(1)   # frame number\n",
    "    ret, frame = capture.read()\n",
    "    test_frame = []\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % samplingRate == 0):    # extracting 1 frames per second\n",
    "        ######################################\n",
    "        #   PROCESS FRAME AND RUN MODEL ON IT\n",
    "        ######################################\n",
    "        count += 1\n",
    "        if count>=skipToCount:\n",
    "            test_frame.append(frame)\n",
    "            test_img = np.array(test_frame)\n",
    "            # resize the image as required by vgg16\n",
    "            test_frame = []\n",
    "            a = resize(test_img[0], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "            test_frame.append(a)\n",
    "            test_img = np.array(test_frame)\n",
    "            # preprocess the image\n",
    "            test_img = preprocess_input(test_img, mode='tf')\n",
    "            # use pretrained model VGG16\n",
    "            test_img = base_model.predict(test_img)\n",
    "            # reshape and center the data\n",
    "            test_img = test_img.reshape(1, 7*7*512)\n",
    "            test_img = test_img / test_img.max()\n",
    "            # predict\n",
    "            test_prediction = model.predict_classes(test_img)\n",
    "            # add item to df if it's the category we are after\n",
    "            if test_prediction[0]==categoryToFind:\n",
    "                skipToCount = count + 2\n",
    "                df = df.append({'Category':2,'FrameID':frameId,'StartTime':startTime}, ignore_index=True)\n",
    "                startTime = math.floor(count/2)\n",
    "                found =True\n",
    "capture.release()\n",
    "if found:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut 3 secs of the video starting there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "0.0\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "3.0\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "18.0\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "28.0\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "29.0\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "if found:\n",
    "    for index,row in df.iterrows():\n",
    "        targetVideo = outputFolder + f\"extract{row['StartTime']:02f}.mp4\"\n",
    "        ffmpeg_extract_subclip(videoFile, row['StartTime'], row['StartTime']+2, targetname=targetVideo)\n",
    "        print(row['StartTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels for images already in CSV file\n",
    "## Classes as follow:\n",
    "0 - neither JERRY nor TOM\n",
    "\n",
    "1 - for JERRY\n",
    "\n",
    "2 - for TOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>FrameID</th>\n",
       "      <th>StartTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3306.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  FrameID  StartTime\n",
       "0       2.0    145.0        0.0\n",
       "1       2.0   1044.0        3.0\n",
       "2       2.0   1624.0       18.0\n",
       "3       2.0   1682.0       28.0\n",
       "4       2.0   1740.0       29.0\n",
       "5       2.0   3306.0       30.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check visualizing a frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
